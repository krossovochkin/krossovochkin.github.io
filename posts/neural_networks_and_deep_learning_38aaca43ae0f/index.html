<!DOCTYPE html>
<html lang="en">
<head>
  
    <title>Neural Networks and Deep Learning :: Krossovochkin — Android Developer</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="description" content="Disclaimer It is brief synopsis of Neural Networks and Deep learning course on Coursera. That course is a first part of Deep learning specialization. Though course is great and very useful, I found that it has a lot of mathematics explanation (linear algebra — matrices, derivatives etc.), so sometimes it was difficult to wait for the actual useful information I didn’t know. So, I think I might be interested in reviewing neural networks in the future, but won’t be able to review course information as there will be a lot of such noise." />
<meta name="keywords" content="" />
<meta name="robots" content="noodp" />
<link rel="canonical" href="https://krossovochkin.github.io/posts/neural_networks_and_deep_learning_38aaca43ae0f/" />




<link rel="stylesheet" href="https://krossovochkin.github.io/assets/style.css">

  <link rel="stylesheet" href="https://krossovochkin.github.io/assets/yellow.css">






<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://krossovochkin.github.io/img/apple-touch-icon-144-precomposed.png">

  <link rel="shortcut icon" href="https://krossovochkin.github.io/img/favicon/yellow.png">



<meta name="twitter:card" content="summary" />

  <meta name="twitter:site" content="krossovochkin" />

<meta name="twitter:creator" content="krossovochkin" />


<meta property="og:locale" content="en" />
<meta property="og:type" content="article" />
<meta property="og:title" content="Neural Networks and Deep Learning :: Krossovochkin">
<meta property="og:description" content="Disclaimer It is brief synopsis of Neural Networks and Deep learning course on Coursera. That course is a first part of Deep learning specialization. Though course is great and very useful, I found that it has a lot of mathematics explanation (linear algebra — matrices, derivatives etc.), so sometimes it was difficult to wait for the actual useful information I didn’t know. So, I think I might be interested in reviewing neural networks in the future, but won’t be able to review course information as there will be a lot of such noise." />
<meta property="og:url" content="https://krossovochkin.github.io/posts/neural_networks_and_deep_learning_38aaca43ae0f/" />
<meta property="og:site_name" content="Neural Networks and Deep Learning" />

  <meta property="og:image" content="https://krossovochkin.github.io/">

<meta property="og:image:width" content="2048">
<meta property="og:image:height" content="1024">


  <meta property="article:published_time" content="2017-11-09 00:00:00 &#43;0000 UTC" />












</head>
<body class="">


<div class="container center headings--one-size">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="/">
  <div class="logo">
    Krossovochkin
  </div>
</a>

    </div>
    <div class="menu-trigger">menu</div>
  </div>
  
    <nav class="menu">
  <ul class="menu__inner menu__inner--desktop">
    
      
        
          <li><a href="/about">About me</a></li>
        
      
        
          <li><a href="/">Posts</a></li>
        
      
      
    

    
  </ul>

  <ul class="menu__inner menu__inner--mobile">
    
      
        <li><a href="/about">About me</a></li>
      
    
      
        <li><a href="/">Posts</a></li>
      
    
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
<div class="post">
  <h1 class="post-title">
    <a href="https://krossovochkin.github.io/posts/neural_networks_and_deep_learning_38aaca43ae0f/">Neural Networks and Deep Learning</a></h1>
  <div class="post-meta">
    
      <span class="post-date">
        2017-11-09 
      </span>
    
    
    <span class="post-author">::
      Vasya Drobushkov
    </span>
    
  </div>

  
  <span class="post-tags">
    
    #<a href="https://krossovochkin.github.io/tags/nn/">NN</a>&nbsp;
    
    #<a href="https://krossovochkin.github.io/tags/neural-networks/">neural networks</a>&nbsp;
    
  </span>
  

  

  

  <div class="post-content"><div>
        <p><a href="https://medium.com/@krossovochkin/neural-networks-and-deep-learning-38aaca43ae0f"><img src="https://img.shields.io/badge/original-medium-green#badge" alt=""></a></p>
<h1 id="disclaimer">Disclaimer<a href="#disclaimer" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h1>
<p>It is brief synopsis of <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome">Neural Networks and Deep learning</a> course on Coursera.
That course is a first part of Deep learning specialization.
Though course is great and very useful, I found that it has a lot of mathematics explanation (linear algebra — matrices, derivatives etc.), so sometimes it was difficult to wait for the actual useful information I didn’t know.
So, I think I might be interested in reviewing neural networks in the future, but won’t be able to review course information as there will be a lot of such noise.
So, I decided to briefly put everything into one page, so I will be able to quickly review this topic in the future.
There will be no code, just formulas as they were explained in a course with some notes on how I understood it.</p>
<h2 id="key-idea">Key idea<a href="#key-idea" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h2>
<p>Neural Network consists of a bunch of parts — neurons.
This emulates to some extent biological neurons in a brain.</p>
<p><img src="../../img/0_zHvdiHDa2MybjQzv.png" alt="Source: https://en.wikipedia.org/wiki/Neuron"><em>Source: <a href="https://en.wikipedia.org/wiki/Neuron">https://en.wikipedia.org/wiki/Neuron</a></em></p>
<p>When building neural network we connect neurons in a special structure like on the picture below:</p>
<p><img src="../../img/1_5egrX--WuyrLA7gBEXdg5A.png" alt="Source: https://hackernoon.com/log-analytics-with-deep-learning-and-machine-learning-20a1891ff70e"><em>Source: <a href="https://hackernoon.com/log-analytics-with-deep-learning-and-machine-learning-20a1891ff70e">https://hackernoon.com/log-analytics-with-deep-learning-and-machine-learning-20a1891ff70e</a></em></p>
<p>Then we use training data (such approach is called “supervised learning”) to learn neurons:</p>
<ul>
<li>
<p>we send our training data as signals through network and receive some output</p>
</li>
<li>
<p>we compare that output with our real test result and send signals back to tell how good or bad the result was</p>
</li>
<li>
<p>repeat multiple times, so neurons are get learned. At each iteration they “work” to produce result, and then receive instructions how they should adjust their work.</p>
</li>
<li>
<p>after neurons are learned enough, we can send to them actual data we want to predict output to</p>
</li>
</ul>
<p>And that’s it. Pretty simple.
And mathematics behind that is pretty simple as well (at least at first course).
The most difficult parts are computational problems, i.e. computer science.</p>
<h2 id="vectorization">Vectorization<a href="#vectorization" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h2>
<p>This is a key concept in a whole theme.
Unfortunately in a course it wasn’t explained well.
In a course it was told that instead of using a loop, you can just call that method in a <a href="http://www.numpy.org/">NumPy</a> library and everything will be faster, as there will be no loop. But what if loop is inside that method and I just don’t see it?</p>
<p>Key thing here is that operations that usually require loops can be done faster if they will be done on a whole array at the same time.
For me it seems that CPU should have such kind of instructions for arrays.
Or maybe it is done with multithreading. I don’t know.
Here all my knowledge is ended.
But it is at least something.</p>
<p>Do not use loops, where there is a way to do operation on a whole array/matrix/vector.
Otherwise much more time might require to complete.</p>
<h2 id="parameters">Parameters<a href="#parameters" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h2>
<p><strong>Given:</strong>
X = A[0] — input
Y — training data (output)
m — number of training examples
L — number of layers
n[L] — number of units in layer L</p>
<p><strong>To find:</strong>
W[L]— matrices of weights
b[L] — bias vectors</p>
<p><strong>Dimensions:</strong></p>
<p><img src="../../img/1_6ugtZP1hlLB2uHUDBOzCBg.png" alt=""></p>
<h2 id="hyperparameters">Hyperparameters<a href="#hyperparameters" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h2>
<p>These parameters should be tuned to get good results.
Changing these values might change learning speed or quality a lot.</p>
<p><img src="../../img/1_tHWagLQM-ttB-DIq_GjvLA.png" alt=""></p>
<h2 id="activation-functions">Activation functions<a href="#activation-functions" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h2>
<h3 id="sigmoid">Sigmoid<a href="#sigmoid" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>
<p>Input: ℝ
Output: (0; 1)</p>
<p><img src="../../img/1_0yGRgHlq3TFVOvWaAMlbxQ.png" alt=""></p>
<p>Good for output layer in classification problems (choose between 0 and 1)</p>
<h3 id="tanh">Tanh<a href="#tanh" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>
<p>Input: ℝ
Output: (-1; 1)</p>
<p><img src="../../img/1_stEFcHA9bWZDfNJnRY6Fmw.png" alt=""></p>
<p>Not very good for output layer.
But better for hidden layers, as provides more balancing than sigmoid.</p>
<h3 id="rectified-linear-unit-relu">Rectified Linear Unit (ReLU)<a href="#rectified-linear-unit-relu" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>
<p>Input: ℝ
Output: [0, + ∞)</p>
<p><img src="../../img/1_CgeZ6yLvdxluNofEVAtvWw.png" alt=""></p>
<p>Good for hidden layers (has bigger gradient, so if tuned can learn faster than tanh)
May be good for output layer if result is a positive real number.
It might be that some neurons are constantly receiving z &lt; 0, in such situation neuron just doesn’t work.</p>
<h3 id="leaky-relu">Leaky ReLU<a href="#leaky-relu" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>
<p>Input: ℝ
Output: [0, + ∞)</p>
<p><img src="../../img/1_jTU2ao64e16ljWpWnXz3XQ.png" alt=""></p>
<p>Improvement of ReLU to not have zeros for negative numbers.</p>
<h2 id="gradient-descend">Gradient descend<a href="#gradient-descend" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h2>
<h3 id="schema">Schema<a href="#schema" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>
<p><img src="../../img/1_TCZ_MpxC-sNmzLxbeIG84A.png" alt="Source: https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome"><em>Source: <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome">https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome</a></em></p>
<h3 id="initialize-parameters">Initialize Parameters<a href="#initialize-parameters" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>
<p>It is important to initialize weight matrices with small numbers, but not zeroes. 
Initializing with zeros will lead to that network will work as a single unit in each layer network (units of the same level would compute same numbers).
Initializing with a big number will probably lead to slower learning, as for sigmoid and tanh gradient will be very slow.</p>
<p>For bias vectors it is OK to initialize them with zeroes.</p>
<p><img src="../../img/1_CZELtiMesFa4cOsb92Ai-Q.png" alt=""></p>
<h3 id="forward-propagation">Forward Propagation<a href="#forward-propagation" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>
<p>For each layer (starting from input layer X = A[0]) compute next values A[L] using parameters on each layer</p>
<p><img src="../../img/1_WUkDLbpQvCsNiGy00HM88A.png" alt=""></p>
<h3 id="compute-cost-function">Compute Cost Function<a href="#compute-cost-function" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>
<p>At the end of forward propagation, compute loss and dA[L] to prepare for backward propagation</p>
<p><img src="../../img/1_WMaAKlQ0Ci68fJ_kCMlR1Q.png" alt=""></p>
<h3 id="backward-propagation">Backward Propagation<a href="#backward-propagation" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>
<p>Compute all dW[L], db[L] to update corresponding parameters</p>
<p><img src="../../img/1_Ds-b33FsTWboJ8nYpeEJ9w.png" alt=""></p>
<h3 id="update-parameters">Update Parameters<a href="#update-parameters" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>
<p>Update parameters and repeat process for a given number of iterations to train neural network</p>
<p><img src="../../img/1_Dh9GNFDHTrSeFoUQ2cKzuA.png" alt=""></p>
<h3 id="predict">Predict<a href="#predict" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>
<p>Do one forward propagation step with calculated weight matrices and bias vectors and input for prediction as X.</p>
<h3 id="and-we-all-done">And we all done<a href="#and-we-all-done" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>

      </div></div>

  
  
<div class="pagination">
    <div class="pagination__title">
        <span class="pagination__title-h">Read other posts</span>
        <hr />
    </div>
    <div class="pagination__buttons">
        
        <span class="button previous">
            <a href="https://krossovochkin.github.io/posts/dynamic_mobile_client_development_problem_and_concept_df509891061/">
                <span class="button__icon">←</span>
                <span class="button__text">Dynamic mobile client development. Problem and concept.</span>
            </a>
        </span>
        
        
        <span class="button next">
            <a href="https://krossovochkin.github.io/posts/android_notifications_overview_and_pitfalls_517d1118ec83/">
                <span class="button__text">[Android] Notifications Overview and Pitfalls</span>
                <span class="button__icon">→</span>
            </a>
        </span>
        
    </div>
</div>

  

  

</div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright copyright--user">
        <span>© 2020 Vasya Drobushkov</span>
    
        <span>:: Theme made by <a href="https://twitter.com/panr">panr</a></span>
      </div>
  </div>
  <div class="footer__inner">
    <div class="copyright copyright--user">
      <a href="https://www.facebook.com/vasya.drobushkov">Facebook</a><a href="https://twitter.com/krossovochkin">Twitter</a>
    </div>
  </div>
</footer>

<script src="https://krossovochkin.github.io/assets/main.js"></script>
<script src="https://krossovochkin.github.io/assets/prism.js"></script>





  
</div>

</body>
</html>
