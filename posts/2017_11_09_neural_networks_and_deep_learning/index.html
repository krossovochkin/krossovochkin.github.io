<!DOCTYPE html>
<html lang="en-us">
<head>
  <title>Neural Networks and Deep Learning</title>

  <link rel="icon" type="image/png" href="favicon.png">
  <link rel="apple-touch-icon" href="apple-touch-icon-144-precompressed.png"/>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet"
      href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.0/styles/androidstudio.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <script src="https://kit.fontawesome.com/6d5aec2882.js" crossorigin="anonymous"></script>

  <link rel="stylesheet" href="/css/style.css" />

  <link rel="me" href="https://androiddev.social/@krossovochkin" />

  
  <meta name="theme-color" content="#1e2327">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Neural Networks and Deep Learning">
  <meta name="twitter:description" content="Disclaimer It is brief synopsis of Neural Networks and Deep learning course on Coursera. That course is a first part of Deep learning specialization. Though course is great and very useful, I found that it has a lot of mathematics explanation (linear algebra — matrices, derivatives etc.), so sometimes it was difficult to wait for the actual useful information I didn’t know. So, I think I might be interested in reviewing neural networks in the future, but won’t be able to review course information as there will be a lot of such noise. So, I decided to briefly put everything into one page, so I will be able to quickly review this topic in the future. There will be no code, just formulas as they were explained in a course with some notes on how I understood it.">

</head>

<body>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-YEWQ4T95D5"></script>
      <script>
        var doNotTrack = false;
        if ( true ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-YEWQ4T95D5');
        }
      </script>

<header>
<nav>
  <ul>
    
    <li class="menu-left"><a href="/about">About</a></li>
    
    <li class="menu-left"><a href="/">Posts</a></li>
    
    <li class="menu-left"><a href="/apps">Apps</a></li>
    
    
    <li class="menu-right"><a rel="me" href="https://t.me/krossovochkin_newsletter" target="_blank"><i class="fa-brands fa-telegram fa-l"></i></a></li>
    
    <li class="menu-right"><a rel="me" href="https://stackoverflow.com/users/1533933/krossovochkin" target="_blank"><i class="fa-brands fa-stack-overflow fa-l"></i></a></li>
    
    <li class="menu-right"><a rel="me" href="https://linkedin.com/in/vasyadrobushkov" target="_blank"><i class="fa-brands fa-linkedin fa-l"></i></a></li>
    
    <li class="menu-right"><a rel="me" href="https://facebook.com/vasya.drobushkov" target="_blank"><i class="fa-brands fa-facebook fa-l"></i></a></li>
    
    <li class="menu-right"><a rel="me" href="/index.xml" target="_blank"><i class="fa-solid fa-rss fa-l"></i></a></li>
    
    <li class="menu-right"><a rel="me" href="https://androiddev.social/@krossovochkin" target="_blank"><i class="fa-brands fa-mastodon fa-l"></i></a></li>
    
    <li class="menu-right"><a rel="me" href="https://github.com/krossovochkin" target="_blank"><i class="fa-brands fa-github fa-l"></i></a></li>
    
  </ul>
</nav>

</header>

<br/>


<div class="meta">

  
    <h1><span class="title">Neural Networks and Deep Learning</span></h1>
  
  
    <h3>November 9, 2017</h3>
  

</div>

<main>
<p><a href="https://medium.com/@krossovochkin/neural-networks-and-deep-learning-38aaca43ae0f"><img src="https://img.shields.io/badge/original-medium-green#badge" alt=""></a></p>
<h1 id="disclaimer">Disclaimer</h1>
<p>It is brief synopsis of <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome">Neural Networks and Deep learning</a> course on Coursera.
That course is a first part of Deep learning specialization.
Though course is great and very useful, I found that it has a lot of mathematics explanation (linear algebra — matrices, derivatives etc.), so sometimes it was difficult to wait for the actual useful information I didn’t know.
So, I think I might be interested in reviewing neural networks in the future, but won’t be able to review course information as there will be a lot of such noise.
So, I decided to briefly put everything into one page, so I will be able to quickly review this topic in the future.
There will be no code, just formulas as they were explained in a course with some notes on how I understood it.</p>
<h2 id="key-idea">Key idea</h2>
<p>Neural Network consists of a bunch of parts — neurons.
This emulates to some extent biological neurons in a brain.</p>
<p><img src="../../img/0_zHvdiHDa2MybjQzv.png" alt="Source: https://en.wikipedia.org/wiki/Neuron"><em>Source: <a href="https://en.wikipedia.org/wiki/Neuron">https://en.wikipedia.org/wiki/Neuron</a></em></p>
<p>When building neural network we connect neurons in a special structure like on the picture below:</p>
<p><img src="../../img/1_5egrX--WuyrLA7gBEXdg5A.png" alt="Source: https://hackernoon.com/log-analytics-with-deep-learning-and-machine-learning-20a1891ff70e"><em>Source: <a href="https://hackernoon.com/log-analytics-with-deep-learning-and-machine-learning-20a1891ff70e">https://hackernoon.com/log-analytics-with-deep-learning-and-machine-learning-20a1891ff70e</a></em></p>
<p>Then we use training data (such approach is called “supervised learning”) to learn neurons:</p>
<ul>
<li>
<p>we send our training data as signals through network and receive some output</p>
</li>
<li>
<p>we compare that output with our real test result and send signals back to tell how good or bad the result was</p>
</li>
<li>
<p>repeat multiple times, so neurons are get learned. At each iteration they “work” to produce result, and then receive instructions how they should adjust their work.</p>
</li>
<li>
<p>after neurons are learned enough, we can send to them actual data we want to predict output to</p>
</li>
</ul>
<p>And that’s it. Pretty simple.
And mathematics behind that is pretty simple as well (at least at first course).
The most difficult parts are computational problems, i.e. computer science.</p>
<h2 id="vectorization">Vectorization</h2>
<p>This is a key concept in a whole theme.
Unfortunately in a course it wasn’t explained well.
In a course it was told that instead of using a loop, you can just call that method in a <a href="http://www.numpy.org/">NumPy</a> library and everything will be faster, as there will be no loop. But what if loop is inside that method and I just don’t see it?</p>
<p>Key thing here is that operations that usually require loops can be done faster if they will be done on a whole array at the same time.
For me it seems that CPU should have such kind of instructions for arrays.
Or maybe it is done with multithreading. I don’t know.
Here all my knowledge is ended.
But it is at least something.</p>
<p>Do not use loops, where there is a way to do operation on a whole array/matrix/vector.
Otherwise much more time might require to complete.</p>
<h2 id="parameters">Parameters</h2>
<p><strong>Given:</strong>
X = A[0] — input
Y — training data (output)
m — number of training examples
L — number of layers
n[L] — number of units in layer L</p>
<p><strong>To find:</strong>
W[L]— matrices of weights
b[L] — bias vectors</p>
<p><strong>Dimensions:</strong></p>
<p><img src="../../img/1_6ugtZP1hlLB2uHUDBOzCBg.png" alt=""></p>
<h2 id="hyperparameters">Hyperparameters</h2>
<p>These parameters should be tuned to get good results.
Changing these values might change learning speed or quality a lot.</p>
<p><img src="../../img/1_tHWagLQM-ttB-DIq_GjvLA.png" alt=""></p>
<h2 id="activation-functions">Activation functions</h2>
<h3 id="sigmoid">Sigmoid</h3>
<p>Input: ℝ
Output: (0; 1)</p>
<p><img src="../../img/1_0yGRgHlq3TFVOvWaAMlbxQ.png" alt=""></p>
<p>Good for output layer in classification problems (choose between 0 and 1)</p>
<h3 id="tanh">Tanh</h3>
<p>Input: ℝ
Output: (-1; 1)</p>
<p><img src="../../img/1_stEFcHA9bWZDfNJnRY6Fmw.png" alt=""></p>
<p>Not very good for output layer.
But better for hidden layers, as provides more balancing than sigmoid.</p>
<h3 id="rectified-linear-unit-relu">Rectified Linear Unit (ReLU)</h3>
<p>Input: ℝ
Output: [0, + ∞)</p>
<p><img src="../../img/1_CgeZ6yLvdxluNofEVAtvWw.png" alt=""></p>
<p>Good for hidden layers (has bigger gradient, so if tuned can learn faster than tanh)
May be good for output layer if result is a positive real number.
It might be that some neurons are constantly receiving z &lt; 0, in such situation neuron just doesn’t work.</p>
<h3 id="leaky-relu">Leaky ReLU</h3>
<p>Input: ℝ
Output: [0, + ∞)</p>
<p><img src="../../img/1_jTU2ao64e16ljWpWnXz3XQ.png" alt=""></p>
<p>Improvement of ReLU to not have zeros for negative numbers.</p>
<h2 id="gradient-descend">Gradient descend</h2>
<h3 id="schema">Schema</h3>
<p><img src="../../img/1_TCZ_MpxC-sNmzLxbeIG84A.png" alt="Source: https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome"><em>Source: <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome">https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome</a></em></p>
<h3 id="initialize-parameters">Initialize Parameters</h3>
<p>It is important to initialize weight matrices with small numbers, but not zeroes.
Initializing with zeros will lead to that network will work as a single unit in each layer network (units of the same level would compute same numbers).
Initializing with a big number will probably lead to slower learning, as for sigmoid and tanh gradient will be very slow.</p>
<p>For bias vectors it is OK to initialize them with zeroes.</p>
<p><img src="../../img/1_CZELtiMesFa4cOsb92Ai-Q.png" alt=""></p>
<h3 id="forward-propagation">Forward Propagation</h3>
<p>For each layer (starting from input layer X = A[0]) compute next values A[L] using parameters on each layer</p>
<p><img src="../../img/1_WUkDLbpQvCsNiGy00HM88A.png" alt=""></p>
<h3 id="compute-cost-function">Compute Cost Function</h3>
<p>At the end of forward propagation, compute loss and dA[L] to prepare for backward propagation</p>
<p><img src="../../img/1_WMaAKlQ0Ci68fJ_kCMlR1Q.png" alt=""></p>
<h3 id="backward-propagation">Backward Propagation</h3>
<p>Compute all dW[L], db[L] to update corresponding parameters</p>
<p><img src="../../img/1_Ds-b33FsTWboJ8nYpeEJ9w.png" alt=""></p>
<h3 id="update-parameters">Update Parameters</h3>
<p>Update parameters and repeat process for a given number of iterations to train neural network</p>
<p><img src="../../img/1_Dh9GNFDHTrSeFoUQ2cKzuA.png" alt=""></p>
<h3 id="predict">Predict</h3>
<p>Do one forward propagation step with calculated weight matrices and bias vectors and input for prediction as X.</p>
<h3 id="and-we-all-done">And we all done</h3>

</main>


<hr/>

<footer>
<nav>
  <ul>
    
    <li class="menu-left"><a href="/about">About</a></li>
    
    <li class="menu-left"><a href="/">Posts</a></li>
    
    <li class="menu-left"><a href="/apps">Apps</a></li>
    
    
    <li class="menu-right"><a rel="me" href="https://t.me/krossovochkin_newsletter" target="_blank"><i class="fa-brands fa-telegram fa-l"></i></a></li>
    
    <li class="menu-right"><a rel="me" href="https://stackoverflow.com/users/1533933/krossovochkin" target="_blank"><i class="fa-brands fa-stack-overflow fa-l"></i></a></li>
    
    <li class="menu-right"><a rel="me" href="https://linkedin.com/in/vasyadrobushkov" target="_blank"><i class="fa-brands fa-linkedin fa-l"></i></a></li>
    
    <li class="menu-right"><a rel="me" href="https://facebook.com/vasya.drobushkov" target="_blank"><i class="fa-brands fa-facebook fa-l"></i></a></li>
    
    <li class="menu-right"><a rel="me" href="/index.xml" target="_blank"><i class="fa-solid fa-rss fa-l"></i></a></li>
    
    <li class="menu-right"><a rel="me" href="https://androiddev.social/@krossovochkin" target="_blank"><i class="fa-brands fa-mastodon fa-l"></i></a></li>
    
    <li class="menu-right"><a rel="me" href="https://github.com/krossovochkin" target="_blank"><i class="fa-brands fa-github fa-l"></i></a></li>
    
  </ul>
</nav>

</footer>


</body>

</html>