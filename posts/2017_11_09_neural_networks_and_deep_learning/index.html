<!DOCTYPE html>
<html lang="en">
    
    


    <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<!-- Enable responsiveness on mobile devices -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="generator" content="Hugo 0.78.2" />

    
    
    

<title>Neural Networks and Deep Learning • Vasya Drobushkov</title>


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Neural Networks and Deep Learning"/>
<meta name="twitter:description" content="Disclaimer It is brief synopsis of Neural Networks and Deep learning course on Coursera. That course is a first part of Deep learning specialization. Though course is great and very useful, I found that it has a lot of mathematics explanation (linear algebra — matrices, derivatives etc.), so sometimes it was difficult to wait for the actual useful information I didn’t know. So, I think I might be interested in reviewing neural networks in the future, but won’t be able to review course information as there will be a lot of such noise."/>

<meta property="og:title" content="Neural Networks and Deep Learning" />
<meta property="og:description" content="Disclaimer It is brief synopsis of Neural Networks and Deep learning course on Coursera. That course is a first part of Deep learning specialization. Though course is great and very useful, I found that it has a lot of mathematics explanation (linear algebra — matrices, derivatives etc.), so sometimes it was difficult to wait for the actual useful information I didn’t know. So, I think I might be interested in reviewing neural networks in the future, but won’t be able to review course information as there will be a lot of such noise." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://krossovochkin.github.io/posts/2017_11_09_neural_networks_and_deep_learning/" />
<meta property="article:published_time" content="2017-11-09T00:00:00+00:00" />
<meta property="article:modified_time" content="2017-11-09T00:00:00+00:00" /><meta property="og:site_name" content="Krossovochkin" />


    


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/androidstudio.min.css">








<link rel="stylesheet" href="/scss/hyde-hyde.adf8a0af011d3afb07ed907ad3295e1c99f49503bc91d395e38dc3f8dfdf4900.css" integrity="sha256-rfigrwEdOvsH7ZB60yleHJn0lQO8kdOV443D&#43;N/fSQA=">


<link rel="stylesheet" href="/scss/print.2744dcbf8a0b2e74f8a50e4b34e5f441be7cf93cc7de27029121c6a09f9e77bc.css" integrity="sha256-J0Tcv4oLLnT4pQ5LNOX0Qb58&#43;TzH3icCkSHGoJ&#43;ed7w=" media="print">



    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="/favicon.png">
    
    

</head>


    <body class="theme-base-0a ">
    
<div class="sidebar">
  <div class="container ">
    <div class="sidebar-about">
      <span class="site__title">
        <a href="https://krossovochkin.github.io/">
        
          Vasya Drobushkov
        
        </a>
      </span>
      
        
        
        
        <div class="author-image">
          <img src="https://krossovochkin.github.io/../img/avatar.png" alt="Author Image" class="img--circle img--headshot element--center">
        </div>
        
      
      
      <p class="site__description">
        
      </p>
    </div>
    <div class="collapsible-menu">
      <input type="checkbox" id="menuToggle">
      <label for="menuToggle">Vasya Drobushkov</label>
      <div class="menu-content">
        <div>
	<ul class="sidebar-nav">
		 
		 
			 
				<li>
					<a href="/posts/">
						<span>Posts</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/about/">
						<span>About</span>
					</a>
				</li>
			 
		
	</ul>
</div>

        <section class="social">
	
	<a href="https://twitter.com/krossovochkin" rel="me"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a>
	
	
	
	<a href="https://facebook.com/vasya.drobushkov" rel="me"><i class="fab fa-facebook-f"></i></a>
	
	
	<a href="https://github.com/krossovochkin" rel="me"><i class="fab fa-github fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	
	<a href="https://linkedin.com/in/vasyadrobushkov" rel="me"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a>
	
	
	
	<a href="https://stackoverflow.com/users/1533933/krossovochkin" rel="me"><i class="fab fa-stack-overflow fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	
	
	
	
	
</section>

      </div>
    </div>
    
<div class="copyright">
  &copy; 2019 - 2020 Vasya Drobushkov
  
    <a href="https://creativecommons.org/licenses/by-sa/4.0">CC BY-SA 4.0</a>
  
</div>



  </div>
</div>

        <div class="content container">
            
    
<article>
  <header>
    <h1>Neural Networks and Deep Learning</h1>
    
    
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Nov 9, 2017
    
    
    
    
    
      
      
          <br/>
           <i class="fas fa-tags"></i>
          
          <a class="badge badge-tag" href="/tags/machine-learning">machine learning</a>
          
      
    
    
    <br/>
    <i class="fas fa-clock"></i> 4 min read
</div>


  </header>
  
  
  <div class="post">
    <p><a href="https://medium.com/@krossovochkin/neural-networks-and-deep-learning-38aaca43ae0f"><img src="https://img.shields.io/badge/original-medium-green#badge" alt=""></a></p>
<h1 id="disclaimer">Disclaimer</h1>
<p>It is brief synopsis of <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome">Neural Networks and Deep learning</a> course on Coursera.
That course is a first part of Deep learning specialization.
Though course is great and very useful, I found that it has a lot of mathematics explanation (linear algebra — matrices, derivatives etc.), so sometimes it was difficult to wait for the actual useful information I didn’t know.
So, I think I might be interested in reviewing neural networks in the future, but won’t be able to review course information as there will be a lot of such noise.
So, I decided to briefly put everything into one page, so I will be able to quickly review this topic in the future.
There will be no code, just formulas as they were explained in a course with some notes on how I understood it.</p>
<h2 id="key-idea">Key idea</h2>
<p>Neural Network consists of a bunch of parts — neurons.
This emulates to some extent biological neurons in a brain.</p>
<p><img src="../../img/0_zHvdiHDa2MybjQzv.png" alt="Source: https://en.wikipedia.org/wiki/Neuron"><em>Source: <a href="https://en.wikipedia.org/wiki/Neuron">https://en.wikipedia.org/wiki/Neuron</a></em></p>
<p>When building neural network we connect neurons in a special structure like on the picture below:</p>
<p><img src="../../img/1_5egrX--WuyrLA7gBEXdg5A.png" alt="Source: https://hackernoon.com/log-analytics-with-deep-learning-and-machine-learning-20a1891ff70e"><em>Source: <a href="https://hackernoon.com/log-analytics-with-deep-learning-and-machine-learning-20a1891ff70e">https://hackernoon.com/log-analytics-with-deep-learning-and-machine-learning-20a1891ff70e</a></em></p>
<p>Then we use training data (such approach is called “supervised learning”) to learn neurons:</p>
<ul>
<li>
<p>we send our training data as signals through network and receive some output</p>
</li>
<li>
<p>we compare that output with our real test result and send signals back to tell how good or bad the result was</p>
</li>
<li>
<p>repeat multiple times, so neurons are get learned. At each iteration they “work” to produce result, and then receive instructions how they should adjust their work.</p>
</li>
<li>
<p>after neurons are learned enough, we can send to them actual data we want to predict output to</p>
</li>
</ul>
<p>And that’s it. Pretty simple.
And mathematics behind that is pretty simple as well (at least at first course).
The most difficult parts are computational problems, i.e. computer science.</p>
<h2 id="vectorization">Vectorization</h2>
<p>This is a key concept in a whole theme.
Unfortunately in a course it wasn’t explained well.
In a course it was told that instead of using a loop, you can just call that method in a <a href="http://www.numpy.org/">NumPy</a> library and everything will be faster, as there will be no loop. But what if loop is inside that method and I just don’t see it?</p>
<p>Key thing here is that operations that usually require loops can be done faster if they will be done on a whole array at the same time.
For me it seems that CPU should have such kind of instructions for arrays.
Or maybe it is done with multithreading. I don’t know.
Here all my knowledge is ended.
But it is at least something.</p>
<p>Do not use loops, where there is a way to do operation on a whole array/matrix/vector.
Otherwise much more time might require to complete.</p>
<h2 id="parameters">Parameters</h2>
<p><strong>Given:</strong>
X = A[0] — input
Y — training data (output)
m — number of training examples
L — number of layers
n[L] — number of units in layer L</p>
<p><strong>To find:</strong>
W[L]— matrices of weights
b[L] — bias vectors</p>
<p><strong>Dimensions:</strong></p>
<p><img src="../../img/1_6ugtZP1hlLB2uHUDBOzCBg.png" alt=""></p>
<h2 id="hyperparameters">Hyperparameters</h2>
<p>These parameters should be tuned to get good results.
Changing these values might change learning speed or quality a lot.</p>
<p><img src="../../img/1_tHWagLQM-ttB-DIq_GjvLA.png" alt=""></p>
<h2 id="activation-functions">Activation functions</h2>
<h3 id="sigmoid">Sigmoid</h3>
<p>Input: ℝ
Output: (0; 1)</p>
<p><img src="../../img/1_0yGRgHlq3TFVOvWaAMlbxQ.png" alt=""></p>
<p>Good for output layer in classification problems (choose between 0 and 1)</p>
<h3 id="tanh">Tanh</h3>
<p>Input: ℝ
Output: (-1; 1)</p>
<p><img src="../../img/1_stEFcHA9bWZDfNJnRY6Fmw.png" alt=""></p>
<p>Not very good for output layer.
But better for hidden layers, as provides more balancing than sigmoid.</p>
<h3 id="rectified-linear-unit-relu">Rectified Linear Unit (ReLU)</h3>
<p>Input: ℝ
Output: [0, + ∞)</p>
<p><img src="../../img/1_CgeZ6yLvdxluNofEVAtvWw.png" alt=""></p>
<p>Good for hidden layers (has bigger gradient, so if tuned can learn faster than tanh)
May be good for output layer if result is a positive real number.
It might be that some neurons are constantly receiving z &lt; 0, in such situation neuron just doesn’t work.</p>
<h3 id="leaky-relu">Leaky ReLU</h3>
<p>Input: ℝ
Output: [0, + ∞)</p>
<p><img src="../../img/1_jTU2ao64e16ljWpWnXz3XQ.png" alt=""></p>
<p>Improvement of ReLU to not have zeros for negative numbers.</p>
<h2 id="gradient-descend">Gradient descend</h2>
<h3 id="schema">Schema</h3>
<p><img src="../../img/1_TCZ_MpxC-sNmzLxbeIG84A.png" alt="Source: https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome"><em>Source: <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome">https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome</a></em></p>
<h3 id="initialize-parameters">Initialize Parameters</h3>
<p>It is important to initialize weight matrices with small numbers, but not zeroes.
Initializing with zeros will lead to that network will work as a single unit in each layer network (units of the same level would compute same numbers).
Initializing with a big number will probably lead to slower learning, as for sigmoid and tanh gradient will be very slow.</p>
<p>For bias vectors it is OK to initialize them with zeroes.</p>
<p><img src="../../img/1_CZELtiMesFa4cOsb92Ai-Q.png" alt=""></p>
<h3 id="forward-propagation">Forward Propagation</h3>
<p>For each layer (starting from input layer X = A[0]) compute next values A[L] using parameters on each layer</p>
<p><img src="../../img/1_WUkDLbpQvCsNiGy00HM88A.png" alt=""></p>
<h3 id="compute-cost-function">Compute Cost Function</h3>
<p>At the end of forward propagation, compute loss and dA[L] to prepare for backward propagation</p>
<p><img src="../../img/1_WMaAKlQ0Ci68fJ_kCMlR1Q.png" alt=""></p>
<h3 id="backward-propagation">Backward Propagation</h3>
<p>Compute all dW[L], db[L] to update corresponding parameters</p>
<p><img src="../../img/1_Ds-b33FsTWboJ8nYpeEJ9w.png" alt=""></p>
<h3 id="update-parameters">Update Parameters</h3>
<p>Update parameters and repeat process for a given number of iterations to train neural network</p>
<p><img src="../../img/1_Dh9GNFDHTrSeFoUQ2cKzuA.png" alt=""></p>
<h3 id="predict">Predict</h3>
<p>Do one forward propagation step with calculated weight matrices and bias vectors and input for prediction as X.</p>
<h3 id="and-we-all-done">And we all done</h3>

  </div>
  

<div class="navigation navigation-single">
    
    <a href="/posts/2017_02_11_android_notifications_overview_and_pitfalls/" class="navigation-prev">
      <i aria-hidden="true" class="fa fa-chevron-left"></i>
      <span class="navigation-tittle">[Android] Notifications Overview and Pitfalls</span>
    </a>
    
    
    <a href="/posts/2018_06_17_fairytales/" class="navigation-next">
      <span class="navigation-tittle">Сказки</span>
      <i aria-hidden="true" class="fa fa-chevron-right"></i>
    </a>
    
</div>


  

  
    


</article>


        </div>
        
    

  
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-148934073-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script defer src="https://use.fontawesome.com/releases/v5.12.1/js/all.js" integrity="sha384-ZbbbT1gw3joYkKRqh0kWyRp32UAvdqkpbLedQJSlnI8iLQcFVxaGyrOgOJiDQTTR" crossorigin="anonymous"></script>


    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
        
            
                <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/languages/bash.min.js"></script>
            
                <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/languages/java.min.js"></script>
            
                <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/languages/kotlin.min.js"></script>
            
        
    <script type="text/javascript">
        
        hljs.configure({languages: ["bash, java, kotlin"]});
        
        hljs.initHighlightingOnLoad();
    </script>
    



    



    </body>
</html>
